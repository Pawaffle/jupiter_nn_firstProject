<html>
<head>
<title>CNN_trees_final.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
.s1 { color: #cf8e6d;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #7a7e85;}
.s5 { color: #2aacb8;}
.ls0 { height: 1px; border-width: 0; color: #43454a; background-color:#43454a}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
CNN_trees_final.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">#%% md 
# Tree classification with CNN <hr class="ls0">#%% md 
We'll build and train a model that uses Convolutional Neural Network (CNN) architecture to classify images of four different tree species: kuusi (spruce), marjakuusi (yew), mänty (pine), and thuja. The model is trained from scratch using our own dataset, notably quite small. <hr class="ls0">#%% md 
### Imports <hr class="ls0">#%% 
</span><span class="s1">import </span><span class="s0">os</span>
<span class="s0">os</span><span class="s2">.</span><span class="s0">environ</span><span class="s2">[</span><span class="s3">'TF_ENABLE_ONEDNN_OPTS'</span><span class="s2">] = </span><span class="s3">'0'</span>

<span class="s1">import </span><span class="s0">shutil</span><span class="s2">, </span><span class="s0">pathlib</span>
<span class="s1">import </span><span class="s0">matplotlib</span><span class="s2">.</span><span class="s0">pyplot </span><span class="s1">as </span><span class="s0">plt</span>
<span class="s1">import </span><span class="s0">keras</span>
<span class="s1">from </span><span class="s0">keras </span><span class="s1">import </span><span class="s0">layers</span><span class="s2">, </span><span class="s0">optimizers</span>
<span class="s1">from </span><span class="s0">keras</span><span class="s2">.</span><span class="s0">utils </span><span class="s1">import </span><span class="s0">image_dataset_from_directory</span>

<span class="s4"># Path to image directory</span>
<span class="s0">images_dir </span><span class="s2">= </span><span class="s0">pathlib</span><span class="s2">.</span><span class="s0">Path</span><span class="s2">(</span><span class="s3">&quot;./NewSet&quot;</span><span class="s2">)</span><hr class="ls0"><span class="s0">#%% md 
### Dataset split <hr class="ls0">#%% md 
The dataset is split into train, validation, and test sets (70/15/15 %) based on their respective subfolders in the directory. The original image size is 800x800 px, but they are resized to 224x224 px to decrease training time. <hr class="ls0">#%% 
train_dataset </span><span class="s2">= </span><span class="s0">image_dataset_from_directory</span><span class="s2">(</span>
    <span class="s0">images_dir </span><span class="s2">/ </span><span class="s3">&quot;train&quot;</span><span class="s2">,</span>
    <span class="s0">image_size </span><span class="s2">= (</span><span class="s5">224</span><span class="s2">, </span><span class="s5">224</span><span class="s2">),</span>
    <span class="s0">batch_size </span><span class="s2">= </span><span class="s5">32</span><span class="s2">)</span>
<span class="s0">validation_dataset </span><span class="s2">= </span><span class="s0">image_dataset_from_directory</span><span class="s2">(</span>
    <span class="s0">images_dir </span><span class="s2">/ </span><span class="s3">&quot;validation&quot;</span><span class="s2">,</span>
    <span class="s0">image_size </span><span class="s2">= (</span><span class="s5">224</span><span class="s2">, </span><span class="s5">224</span><span class="s2">),</span>
    <span class="s0">batch_size </span><span class="s2">= </span><span class="s5">32</span><span class="s2">)</span>
<span class="s0">test_dataset </span><span class="s2">= </span><span class="s0">image_dataset_from_directory</span><span class="s2">(</span>
    <span class="s0">images_dir </span><span class="s2">/ </span><span class="s3">&quot;test&quot;</span><span class="s2">,</span>
    <span class="s0">image_size </span><span class="s2">= (</span><span class="s5">224</span><span class="s2">, </span><span class="s5">224</span><span class="s2">),</span>
    <span class="s0">batch_size </span><span class="s2">= </span><span class="s5">32</span><span class="s2">)</span>

<span class="s4"># Make sure all 4 classes are present in all 3 datasets</span>
<span class="s0">print</span><span class="s2">(</span><span class="s0">train_dataset</span><span class="s2">.</span><span class="s0">class_names</span><span class="s2">, </span><span class="s0">validation_dataset</span><span class="s2">.</span><span class="s0">class_names</span><span class="s2">, </span><span class="s0">test_dataset</span><span class="s2">.</span><span class="s0">class_names</span><span class="s2">)</span><hr class="ls0"><span class="s0">#%% md 
### Data augmentation <hr class="ls0">#%% md 
Data augmentation is implemented to improve generalization, especially since we're using a very small dataset. <hr class="ls0">#%% 
data_augmentation </span><span class="s2">= </span><span class="s0">keras</span><span class="s2">.</span><span class="s0">Sequential</span><span class="s2">([</span>
    <span class="s0">layers</span><span class="s2">.</span><span class="s0">RandomFlip</span><span class="s2">(</span><span class="s3">&quot;horizontal&quot;</span><span class="s2">),</span>
    <span class="s0">layers</span><span class="s2">.</span><span class="s0">RandomRotation</span><span class="s2">(</span><span class="s5">0.1</span><span class="s2">),</span>
    <span class="s0">layers</span><span class="s2">.</span><span class="s0">RandomZoom</span><span class="s2">(</span><span class="s5">0.2</span><span class="s2">)</span>
<span class="s2">])</span>

<span class="s4"># Visualize a result of data augmentation</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">figure</span><span class="s2">(</span><span class="s0">figsize</span><span class="s2">=(</span><span class="s5">10</span><span class="s2">, </span><span class="s5">10</span><span class="s2">))</span>
<span class="s1">for </span><span class="s0">images</span><span class="s2">, </span><span class="s0">_ </span><span class="s1">in </span><span class="s0">train_dataset</span><span class="s2">.</span><span class="s0">take</span><span class="s2">(</span><span class="s5">1</span><span class="s2">):</span>
    <span class="s1">for </span><span class="s0">i </span><span class="s1">in </span><span class="s0">range</span><span class="s2">(</span><span class="s5">9</span><span class="s2">):</span>
        <span class="s0">augmented_images </span><span class="s2">= </span><span class="s0">data_augmentation</span><span class="s2">(</span><span class="s0">images</span><span class="s2">, </span><span class="s0">training</span><span class="s2">=</span><span class="s1">True</span><span class="s2">)</span>
        <span class="s0">ax </span><span class="s2">= </span><span class="s0">plt</span><span class="s2">.</span><span class="s0">subplot</span><span class="s2">(</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s0">i</span><span class="s2">+</span><span class="s5">1</span><span class="s2">)</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">imshow</span><span class="s2">(</span><span class="s0">augmented_images</span><span class="s2">[</span><span class="s5">0</span><span class="s2">].</span><span class="s0">numpy</span><span class="s2">().</span><span class="s0">astype</span><span class="s2">(</span><span class="s3">&quot;uint8&quot;</span><span class="s2">))</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">axis</span><span class="s2">(</span><span class="s3">&quot;off&quot;</span><span class="s2">)</span>

<span class="s1">for </span><span class="s0">images</span><span class="s2">, </span><span class="s0">labels </span><span class="s1">in </span><span class="s0">train_dataset</span><span class="s2">.</span><span class="s0">take</span><span class="s2">(</span><span class="s5">1</span><span class="s2">):</span>
    <span class="s0">print</span><span class="s2">(</span><span class="s0">labels</span><span class="s2">)</span>
    <span class="s1">break</span><hr class="ls0"><span class="s0">#%% md 
### Defining the model <hr class="ls0">#%% md 
The CNN is defined to classify images of four different tree species. The process starts with data augmentation and rescaling. It includes a stack of convolutional and pooling layers, and then the extracted features are flattened and passed through a dropout layer and a dense output layer with a softmax activation to produce probabilities for four differenct classes. <hr class="ls0">#%% 
inputs </span><span class="s2">= </span><span class="s0">keras</span><span class="s2">.</span><span class="s0">Input</span><span class="s2">(</span><span class="s0">shape</span><span class="s2">=(</span><span class="s5">224</span><span class="s2">, </span><span class="s5">224</span><span class="s2">, </span><span class="s5">3</span><span class="s2">))</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">data_augmentation</span><span class="s2">(</span><span class="s0">inputs</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Rescaling</span><span class="s2">(</span><span class="s5">1.0</span><span class="s2">/</span><span class="s5">255</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Conv2D</span><span class="s2">(</span><span class="s0">filters</span><span class="s2">=</span><span class="s5">32</span><span class="s2">, </span><span class="s0">kernel_size</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;relu&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">MaxPooling2D</span><span class="s2">(</span><span class="s0">pool_size</span><span class="s2">=</span><span class="s5">2</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Conv2D</span><span class="s2">(</span><span class="s0">filters</span><span class="s2">=</span><span class="s5">64</span><span class="s2">, </span><span class="s0">kernel_size</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;relu&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">MaxPooling2D</span><span class="s2">(</span><span class="s0">pool_size</span><span class="s2">=</span><span class="s5">2</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Conv2D</span><span class="s2">(</span><span class="s0">filters</span><span class="s2">=</span><span class="s5">128</span><span class="s2">, </span><span class="s0">kernel_size</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;relu&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">MaxPooling2D</span><span class="s2">(</span><span class="s0">pool_size</span><span class="s2">=</span><span class="s5">2</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Conv2D</span><span class="s2">(</span><span class="s0">filters</span><span class="s2">=</span><span class="s5">256</span><span class="s2">, </span><span class="s0">kernel_size</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;relu&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">MaxPooling2D</span><span class="s2">(</span><span class="s0">pool_size</span><span class="s2">=</span><span class="s5">2</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Conv2D</span><span class="s2">(</span><span class="s0">filters</span><span class="s2">=</span><span class="s5">256</span><span class="s2">, </span><span class="s0">kernel_size</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;relu&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>

<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Flatten</span><span class="s2">()(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">x </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Dropout</span><span class="s2">(</span><span class="s5">0.3</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">) </span><span class="s4"># smaller dropout to eliminate fluctuation in val loss/acc</span>

<span class="s0">outputs </span><span class="s2">= </span><span class="s0">layers</span><span class="s2">.</span><span class="s0">Dense</span><span class="s2">(</span><span class="s5">4</span><span class="s2">, </span><span class="s0">activation</span><span class="s2">=</span><span class="s3">&quot;softmax&quot;</span><span class="s2">)(</span><span class="s0">x</span><span class="s2">)</span>
<span class="s0">model </span><span class="s2">= </span><span class="s0">keras</span><span class="s2">.</span><span class="s0">Model</span><span class="s2">(</span><span class="s0">inputs</span><span class="s2">=</span><span class="s0">inputs</span><span class="s2">, </span><span class="s0">outputs</span><span class="s2">=</span><span class="s0">outputs</span><span class="s2">)</span>

<span class="s0">model</span><span class="s2">.</span><span class="s0">summary</span><span class="s2">()</span><hr class="ls0"><span class="s0">#%% md 
### Compiling the model <hr class="ls0">#%% md 
The CNN is compiled using the Adam optimizer with a learning rate of 0.0003 due to the small amount of data in each batch. A lower learning rate ensures stability in training the model. <hr class="ls0">#%% 
model</span><span class="s2">.</span><span class="s0">compile</span><span class="s2">(</span>
    <span class="s0">loss</span><span class="s2">=</span><span class="s3">&quot;sparse_categorical_crossentropy&quot;</span><span class="s2">,</span>
    <span class="s0">optimizer </span><span class="s2">= </span><span class="s0">optimizers</span><span class="s2">.</span><span class="s0">Adam</span><span class="s2">(</span><span class="s0">learning_rate</span><span class="s2">=</span><span class="s5">0.0003</span><span class="s2">),</span>
    <span class="s0">metrics</span><span class="s2">=[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">]</span>
<span class="s2">)</span>

<span class="s4"># Print a single batch to confirm the correct shape and labels of the images</span>
<span class="s1">for </span><span class="s0">data_batch</span><span class="s2">, </span><span class="s0">labels_batch </span><span class="s1">in </span><span class="s0">train_dataset</span><span class="s2">:</span>
    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;data batch shape:&quot;</span><span class="s2">, </span><span class="s0">data_batch</span><span class="s2">.</span><span class="s0">shape</span><span class="s2">)</span>
    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;labels batch shape:&quot;</span><span class="s2">, </span><span class="s0">labels_batch</span><span class="s2">.</span><span class="s0">shape</span><span class="s2">)</span>
    <span class="s1">break</span><hr class="ls0"><span class="s0">#%% md 
### Training the model <hr class="ls0">#%% md 
The CNN is trained on the training dataset for 20 epochs, while evaluating its performance using the validation set each epoch. A ModelCheckpoint callback is used to automatically save the version of the model that achieves the lowest validation loss for later testing. <hr class="ls0">#%% 
callbacks </span><span class="s2">= [</span><span class="s0">keras</span><span class="s2">.</span><span class="s0">callbacks</span><span class="s2">.</span><span class="s0">ModelCheckpoint</span><span class="s2">(</span>
    <span class="s0">filepath</span><span class="s2">=</span><span class="s3">&quot;convnet_from_scratch_with_augmentation.keras&quot;</span><span class="s2">,</span>
    <span class="s0">save_best_only</span><span class="s2">=</span><span class="s1">True</span><span class="s2">,</span>
    <span class="s0">monitor</span><span class="s2">=</span><span class="s3">&quot;val_loss&quot;</span>
<span class="s2">)]</span>

<span class="s0">history </span><span class="s2">= </span><span class="s0">model</span><span class="s2">.</span><span class="s0">fit</span><span class="s2">(</span>
    <span class="s0">train_dataset</span><span class="s2">,</span>
    <span class="s0">epochs </span><span class="s2">= </span><span class="s5">20</span><span class="s2">,</span>
    <span class="s0">validation_data</span><span class="s2">=</span><span class="s0">validation_dataset</span><span class="s2">,</span>
    <span class="s0">callbacks </span><span class="s2">= </span><span class="s0">callbacks</span>
<span class="s2">)</span><hr class="ls0"><span class="s0">#%% md 
### Visualizing results <hr class="ls0">#%% md 
The training and validation accuracy and loss over the epochs are visualized to assess the model’s learning progress. <hr class="ls0">#%% 
accuracy </span><span class="s2">= </span><span class="s0">history</span><span class="s2">.</span><span class="s0">history</span><span class="s2">[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">]</span>
<span class="s0">val_accuracy </span><span class="s2">= </span><span class="s0">history</span><span class="s2">.</span><span class="s0">history</span><span class="s2">[</span><span class="s3">&quot;val_accuracy&quot;</span><span class="s2">]</span>
<span class="s0">loss </span><span class="s2">= </span><span class="s0">history</span><span class="s2">.</span><span class="s0">history</span><span class="s2">[</span><span class="s3">&quot;loss&quot;</span><span class="s2">]</span>
<span class="s0">val_loss </span><span class="s2">= </span><span class="s0">history</span><span class="s2">.</span><span class="s0">history</span><span class="s2">[</span><span class="s3">&quot;val_loss&quot;</span><span class="s2">]</span>
<span class="s0">epochs </span><span class="s2">= </span><span class="s0">list</span><span class="s2">(</span><span class="s0">range</span><span class="s2">(</span><span class="s5">1</span><span class="s2">, </span><span class="s0">len</span><span class="s2">(</span><span class="s0">accuracy</span><span class="s2">)+</span><span class="s5">1</span><span class="s2">))</span>

<span class="s0">plt</span><span class="s2">.</span><span class="s0">plot</span><span class="s2">(</span><span class="s0">epochs</span><span class="s2">, </span><span class="s0">accuracy</span><span class="s2">, </span><span class="s0">label</span><span class="s2">=</span><span class="s3">&quot;Training accuracy&quot;</span><span class="s2">, </span><span class="s0">color</span><span class="s2">=</span><span class="s3">&quot;brown&quot;</span><span class="s2">)</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">plot</span><span class="s2">(</span><span class="s0">epochs</span><span class="s2">, </span><span class="s0">val_accuracy</span><span class="s2">, </span><span class="s0">label</span><span class="s2">=</span><span class="s3">&quot;Validation accuracy&quot;</span><span class="s2">, </span><span class="s0">color</span><span class="s2">=</span><span class="s3">&quot;blue&quot;</span><span class="s2">)</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">legend</span><span class="s2">()</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">figure</span><span class="s2">()</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">plot</span><span class="s2">(</span><span class="s0">epochs</span><span class="s2">, </span><span class="s0">loss</span><span class="s2">, </span><span class="s0">label</span><span class="s2">=</span><span class="s3">&quot;Training loss&quot;</span><span class="s2">, </span><span class="s0">color</span><span class="s2">=</span><span class="s3">&quot;brown&quot;</span><span class="s2">)</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">plot</span><span class="s2">(</span><span class="s0">epochs</span><span class="s2">, </span><span class="s0">val_loss</span><span class="s2">, </span><span class="s0">label</span><span class="s2">=</span><span class="s3">&quot;Validation loss&quot;</span><span class="s2">, </span><span class="s0">color</span><span class="s2">=</span><span class="s3">&quot;blue&quot;</span><span class="s2">)</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">legend</span><span class="s2">()</span>
<span class="s0">plt</span><span class="s2">.</span><span class="s0">show</span><span class="s2">()</span><hr class="ls0"><span class="s0">#%% md 
The training accuracy steadily increases and reaches above 80%, indicating that the model is learning the training data well. However, the validation accuracy fluctuates a lot between epochs, likely due to the small size of the validation set. Similarly, the training loss decreases smoothly, while the validation shows large spikes, which points to the same issue. Overall, the model is learning meaningful features, but the validation metrics are noisy, albeit unsurprisingly. <hr class="ls0">#%% md 
### Testing the model <hr class="ls0">#%% md 
The best performing model that was saved using a callback is evaluated using the test set to measure its true accuracy. <hr class="ls0">#%% 
test_model </span><span class="s2">= </span><span class="s0">keras</span><span class="s2">.</span><span class="s0">models</span><span class="s2">.</span><span class="s0">load_model</span><span class="s2">(</span><span class="s3">&quot;convnet_from_scratch_with_augmentation.keras&quot;</span><span class="s2">)</span>
<span class="s0">test_loss</span><span class="s2">, </span><span class="s0">test_acc </span><span class="s2">= </span><span class="s0">test_model</span><span class="s2">.</span><span class="s0">evaluate</span><span class="s2">(</span><span class="s0">test_dataset</span><span class="s2">)</span>
<span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;Test accuracy: </span><span class="s1">{</span><span class="s0">test_acc</span><span class="s1">:</span><span class="s3">.3f</span><span class="s1">}</span><span class="s3">&quot;</span><span class="s2">)</span><hr class="ls0"><span class="s0">#%% md 
The accuracy seems to be quite good considering the model was built from scratch on such a small dataset instead of using a pre-trained one. <hr class="ls0">#%% 
</span><span class="s1">import </span><span class="s0">numpy </span><span class="s1">as </span><span class="s0">np</span>
<span class="s1">import </span><span class="s0">matplotlib</span><span class="s2">.</span><span class="s0">pyplot </span><span class="s1">as </span><span class="s0">plt</span>

<span class="s4"># 1. Collect all test data and labels</span>
<span class="s4"># We extract the data manually so we can index it to show specific images</span>
<span class="s0">x_test </span><span class="s2">= []</span>
<span class="s0">y_true </span><span class="s2">= []</span>

<span class="s1">for </span><span class="s0">images</span><span class="s2">, </span><span class="s0">labels </span><span class="s1">in </span><span class="s0">test_dataset</span><span class="s2">:</span>
    <span class="s0">x_test</span><span class="s2">.</span><span class="s0">append</span><span class="s2">(</span><span class="s0">images</span><span class="s2">.</span><span class="s0">numpy</span><span class="s2">())</span>
    <span class="s0">y_true</span><span class="s2">.</span><span class="s0">append</span><span class="s2">(</span><span class="s0">labels</span><span class="s2">.</span><span class="s0">numpy</span><span class="s2">())</span>

<span class="s0">x_test </span><span class="s2">= </span><span class="s0">np</span><span class="s2">.</span><span class="s0">concatenate</span><span class="s2">(</span><span class="s0">x_test</span><span class="s2">, </span><span class="s0">axis</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
<span class="s0">y_true </span><span class="s2">= </span><span class="s0">np</span><span class="s2">.</span><span class="s0">concatenate</span><span class="s2">(</span><span class="s0">y_true</span><span class="s2">, </span><span class="s0">axis</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

<span class="s4"># 2. Get predictions</span>
<span class="s4"># IMPORTANT: In this notebook, your model variable is 'test_model'</span>
<span class="s0">y_pred_probs </span><span class="s2">= </span><span class="s0">test_model</span><span class="s2">.</span><span class="s0">predict</span><span class="s2">(</span><span class="s0">x_test</span><span class="s2">)</span>
<span class="s0">y_pred_classes </span><span class="s2">= </span><span class="s0">np</span><span class="s2">.</span><span class="s0">argmax</span><span class="s2">(</span><span class="s0">y_pred_probs</span><span class="s2">, </span><span class="s0">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>
<span class="s0">class_names </span><span class="s2">= </span><span class="s0">test_dataset</span><span class="s2">.</span><span class="s0">class_names</span>

<span class="s4"># 3. Find ONLY mistakes</span>
<span class="s0">mistake_indices </span><span class="s2">= </span><span class="s0">np</span><span class="s2">.</span><span class="s0">where</span><span class="s2">(</span><span class="s0">y_pred_classes </span><span class="s2">!= </span><span class="s0">y_true</span><span class="s2">)[</span><span class="s5">0</span><span class="s2">]</span>

<span class="s1">if </span><span class="s0">len</span><span class="s2">(</span><span class="s0">mistake_indices</span><span class="s2">) == </span><span class="s5">0</span><span class="s2">:</span>
    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;</span><span class="s1">\n</span><span class="s3">SUCCESS: The model made 0 mistakes! (Accuracy is 100%)&quot;</span><span class="s2">)</span>
<span class="s1">else</span><span class="s2">:</span>
    <span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s1">\n</span><span class="s3">Found </span><span class="s1">{</span><span class="s0">len</span><span class="s2">(</span><span class="s0">mistake_indices</span><span class="s2">)</span><span class="s1">} </span><span class="s3">mistakes.&quot;</span><span class="s2">)</span>

    <span class="s4"># Show only the mistakes</span>
    <span class="s1">for </span><span class="s0">k </span><span class="s1">in </span><span class="s0">mistake_indices</span><span class="s2">:</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">figure</span><span class="s2">(</span><span class="s0">figsize</span><span class="s2">=(</span><span class="s5">10</span><span class="s2">, </span><span class="s5">3</span><span class="s2">))</span>

        <span class="s4"># Image</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">subplot</span><span class="s2">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">)</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">imshow</span><span class="s2">(</span><span class="s0">x_test</span><span class="s2">[</span><span class="s0">k</span><span class="s2">].</span><span class="s0">astype</span><span class="s2">(</span><span class="s3">&quot;uint8&quot;</span><span class="s2">))</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">axis</span><span class="s2">(</span><span class="s3">'off'</span><span class="s2">)</span>

        <span class="s4"># Bar chart of probabilities</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">subplot</span><span class="s2">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)</span>
        <span class="s0">probs </span><span class="s2">= </span><span class="s0">y_pred_probs</span><span class="s2">[</span><span class="s0">k</span><span class="s2">]</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">bar</span><span class="s2">(</span><span class="s0">np</span><span class="s2">.</span><span class="s0">arange</span><span class="s2">(</span><span class="s0">len</span><span class="s2">(</span><span class="s0">class_names</span><span class="s2">)), </span><span class="s0">probs</span><span class="s2">)</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">xticks</span><span class="s2">(</span><span class="s0">np</span><span class="s2">.</span><span class="s0">arange</span><span class="s2">(</span><span class="s0">len</span><span class="s2">(</span><span class="s0">class_names</span><span class="s2">)), </span><span class="s0">class_names</span><span class="s2">, </span><span class="s0">rotation</span><span class="s2">=</span><span class="s5">45</span><span class="s2">)</span>

        <span class="s0">pred_label </span><span class="s2">= </span><span class="s0">class_names</span><span class="s2">[</span><span class="s0">y_pred_classes</span><span class="s2">[</span><span class="s0">k</span><span class="s2">]]</span>
        <span class="s0">true_label </span><span class="s2">= </span><span class="s0">class_names</span><span class="s2">[</span><span class="s0">y_true</span><span class="s2">[</span><span class="s0">k</span><span class="s2">]]</span>

        <span class="s4"># Title is RED for mistakes</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">ylabel</span><span class="s2">(</span><span class="s3">&quot;Probability&quot;</span><span class="s2">)</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">title</span><span class="s2">(</span><span class="s3">f&quot;Predicted: </span><span class="s1">{</span><span class="s0">pred_label</span><span class="s1">} </span><span class="s3">| True: </span><span class="s1">{</span><span class="s0">true_label</span><span class="s1">}</span><span class="s3">&quot;</span><span class="s2">, </span><span class="s0">color</span><span class="s2">=</span><span class="s3">'red'</span><span class="s2">, </span><span class="s0">fontweight</span><span class="s2">=</span><span class="s3">'bold'</span><span class="s2">)</span>

        <span class="s0">plt</span><span class="s2">.</span><span class="s0">tight_layout</span><span class="s2">()</span>
        <span class="s0">plt</span><span class="s2">.</span><span class="s0">show</span><span class="s2">()</span>
</pre>
</body>
</html>